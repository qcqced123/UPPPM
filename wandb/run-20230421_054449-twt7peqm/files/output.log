Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']
- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                        | 0/1219 [00:00<?, ?it/s]
  grad_norm = torch.nn.utils.clip_grad_norm(                                                                                 | 0/1219 [00:00<?, ?it/s]


















































































































































































































































































































































/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "






















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 478/480 [00:45<00:00, 10.56it/s]
[1/12] Train Loss: 0.6269999742507935
[1/12] Valid Loss: 0.6085000038146973
[1/12] Pearson Score: 0.7493
[1/12] Gradient Norm: 993.4425048828125
[1/12] lr: 1.6666666666666667e-05
[Update] Valid Score : (-inf => 0.7493) Save Parameter
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 480/480 [00:45<00:00, 10.55it/s]
  0%|                                                                                                                        | 0/1219 [00:00<?, ?it/s]



















































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1219/1219 [11:20<00:00,  1.79it/s]






















 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 476/480 [00:45<00:00, 10.57it/s]
[2/12] Train Loss: 0.5800999999046326
[2/12] Valid Loss: 0.5950999855995178
[2/12] Pearson Score: 0.7819
[2/12] Gradient Norm: 882.6365966796875
[2/12] lr: 1.8936326403234125e-05
[Update] Valid Score : (0.7493 => 0.7819) Save Parameter

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 480/480 [00:45<00:00, 10.59it/s]
[3/12] Train & Validation


















































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1219/1219 [11:19<00:00,  1.80it/s]






















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 478/480 [00:45<00:00, 10.53it/s]
[3/12] Train Loss: 0.5580000281333923
[3/12] Valid Loss: 0.5884000062942505
[3/12] Pearson Score: 0.8008
[3/12] Gradient Norm: 1000.1387939453125
[3/12] lr: 1.5000000000000002e-05
[Update] Valid Score : (0.7819 => 0.8008) Save Parameter
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 480/480 [00:45<00:00, 10.55it/s]
  0%|                                                                                                                        | 0/1219 [00:00<?, ?it/s]



















































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1219/1219 [11:19<00:00,  1.79it/s]






















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 478/480 [00:45<00:00, 10.57it/s]
[4/12] Train Loss: 0.5443999767303467
[4/12] Valid Loss: 0.5848000049591064
[4/12] Pearson Score: 0.817
[4/12] Gradient Norm: 981.3222045898438
[4/12] lr: 9.418551710895243e-06
[Update] Valid Score : (0.8008 => 0.8170) Save Parameter

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 480/480 [00:45<00:00, 10.60it/s]
[5/12] Train & Validation


















































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1219/1219 [11:19<00:00,  1.80it/s]























100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 480/480 [00:45<00:00, 10.52it/s]
[5/12] Train Loss: 0.5338000059127808
[5/12] Valid Loss: 0.5809000134468079
[5/12] Pearson Score: 0.8205
[5/12] Gradient Norm: 861.857421875
[5/12] lr: 4.028414082972141e-06
[Update] Valid Score : (0.8170 => 0.8205) Save Parameter
Best Score: 0.8204564824509224
[6/12] Train & Validation


















































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1219/1219 [11:19<00:00,  1.80it/s]






















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 478/480 [00:45<00:00, 10.47it/s]
[6/12] Train Loss: 0.5278000235557556
[6/12] Valid Loss: 0.5863999724388123
[6/12] Pearson Score: 0.8196
[6/12] Gradient Norm: 968.186279296875
[6/12] lr: 6.030737921409169e-07
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 480/480 [00:45<00:00, 10.51it/s]


















































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1219/1219 [11:18<00:00,  1.79it/s]





















100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 480/480 [00:45<00:00, 10.57it/s]
  0%|                                                                                                                        | 0/1219 [00:00<?, ?it/s]
[7/12] Train Loss: 0.5304999947547913
[7/12] Valid Loss: 0.5965999960899353
[7/12] Pearson Score: 0.8037
[7/12] Gradient Norm: 971.4364013671875
[7/12] lr: 1.973044870579824e-05

























































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1219/1219 [11:35<00:00,  1.75it/s]























100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 479/480 [00:46<00:00, 10.17it/s]
[8/12] Train Loss: 0.5371999740600586
[8/12] Valid Loss: 0.5963000059127808
[8/12] Pearson Score: 0.8074
[8/12] Gradient Norm: 990.8880004882812
[8/12] lr: 1.6862416378687336e-05
Early STOP