Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']
- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                        | 0/1273 [00:00<?, ?it/s]
  grad_norm = torch.nn.utils.clip_grad_norm(                                                                                 | 0/1273 [00:00<?, ?it/s]





























































































































































































































































































































































/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "



















 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 422/426 [00:39<00:00, 10.59it/s]
[1/12] Train Loss: 0.6287999749183655
[1/12] Valid Loss: 0.5878999829292297
[1/12] Pearson Score: 0.7636
[1/12] Gradient Norm: 984.6848754882812
[1/12] lr: 1.6666666666666667e-05
[Update] Valid Score : (-inf => 0.7636) Save Parameter
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:40<00:00, 10.59it/s]
  0%|                                                                                                                        | 0/1273 [00:00<?, ?it/s]







































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1273/1273 [11:58<00:00,  1.79it/s]



















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 425/426 [00:40<00:00, 10.60it/s]
[2/12] Train Loss: 0.583299994468689
[2/12] Valid Loss: 0.5753999948501587
[2/12] Pearson Score: 0.8076
[2/12] Gradient Norm: 1000.1557006835938
[2/12] lr: 1.8936326403234125e-05
[Update] Valid Score : (0.7636 => 0.8076) Save Parameter
Best Score: 0.8075844198625369
  0%|                                                                                                                        | 0/1273 [00:00<?, ?it/s]































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1273/1273 [11:43<00:00,  1.83it/s]




















100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:39<00:00, 10.63it/s]
[3/12] Train Loss: 0.5641000270843506
[3/12] Valid Loss: 0.5691999793052673
[3/12] Pearson Score: 0.8207
[3/12] Gradient Norm: 1001.2681884765625
[3/12] lr: 1.5000000000000002e-05
[Update] Valid Score : (0.8076 => 0.8207) Save Parameter
Best Score: 0.8206664007879841
[4/12] Train & Validation



























































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1273/1273 [11:41<00:00,  1.81it/s]




















100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:40<00:00, 10.57it/s]
[4/12] Train Loss: 0.546999990940094
[4/12] Valid Loss: 0.5687999725341797
[4/12] Pearson Score: 0.8298
[4/12] Gradient Norm: 974.00830078125
[4/12] lr: 9.418551710895243e-06
[Update] Valid Score : (0.8207 => 0.8298) Save Parameter
Best Score: 0.8297560355508488
  0%|                                                                                                                        | 0/1273 [00:00<?, ?it/s]

































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1273/1273 [11:47<00:00,  1.81it/s]




















100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:40<00:00, 10.61it/s]
[5/12] Train Loss: 0.5382999777793884
[5/12] Valid Loss: 0.5706999897956848
[5/12] Pearson Score: 0.8306
[5/12] Gradient Norm: 721.4044189453125
[5/12] lr: 4.028414082972141e-06
[Update] Valid Score : (0.8298 => 0.8306) Save Parameter
Best Score: 0.8305930357811099
  0%|▏                                                                                                               | 2/1273 [00:01<11:35,  1.83it/s]































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1273/1273 [11:47<00:00,  1.81it/s]




















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 425/426 [00:40<00:00, 10.56it/s]
[6/12] Train Loss: 0.5318999886512756
[6/12] Valid Loss: 0.5694000124931335
[6/12] Pearson Score: 0.8353
[6/12] Gradient Norm: 992.694580078125
[6/12] lr: 6.030737921409169e-07
[Update] Valid Score : (0.8306 => 0.8353) Save Parameter
Best Score: 0.835268734207016
  0%|                                                                                                                        | 0/1273 [00:00<?, ?it/s]

































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1273/1273 [11:47<00:00,  1.81it/s]



















100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:40<00:00, 10.57it/s]
  0%|▎                                                                                                               | 3/1273 [00:01<11:40,  1.81it/s]
[7/12] Train Loss: 0.535099983215332
[7/12] Valid Loss: 0.5932999849319458
[7/12] Pearson Score: 0.8193
[7/12] Gradient Norm: 985.6030883789062
[7/12] lr: 1.973044870579824e-05
































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1273/1273 [11:47<00:00,  1.78it/s]



















100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:40<00:00, 10.59it/s]
  0%|                                                                                                                        | 0/1273 [00:00<?, ?it/s]
[8/12] Train Loss: 0.5442000031471252
[8/12] Valid Loss: 0.588699996471405
[8/12] Pearson Score: 0.7988
[8/12] Gradient Norm: 992.3541870117188
[8/12] lr: 1.6862416378687336e-05



































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1273/1273 [11:51<00:00,  1.78it/s]



















 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 422/426 [00:39<00:00, 10.54it/s]
[9/12] Train Loss: 0.5331000089645386
[9/12] Valid Loss: 0.5753999948501587
[9/12] Pearson Score: 0.8204
[9/12] Gradient Norm: 990.5106201171875
[9/12] lr: 1.1736481776669307e-05

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:40<00:00, 10.55it/s]