Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight']
- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                         | 0/81 [00:00<?, ?it/s]
  grad_norm = torch.nn.utils.clip_grad_norm(                                                                                  | 0/81 [00:00<?, ?it/s]















































































/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "





















 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 25/26 [00:45<00:01,  1.77s/it]
[1/6] Train Loss: 0.6223000288009644
[1/6] Valid Loss: 0.5756999850273132
[1/6] Pearson Score: 0.7554
[1/6] Gradient Norm: 309.92498779296875
[1/6] lr: 4.931918844650095e-05
[Update] Valid Score : (-inf => 0.7554) Save Parameter
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:45<00:00,  1.41s/it]
  0%|                                                                                                                         | 0/81 [00:00<?, ?it/s]
















































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81/81 [10:41<00:00,  7.54s/it]





















 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 25/26 [00:43<00:01,  1.72s/it]
[2/6] Train Loss: 0.5608000159263611
[2/6] Valid Loss: 0.569100022315979
[2/6] Pearson Score: 0.7952
[2/6] Gradient Norm: 454.71240234375
[2/6] lr: 4.211236596444096e-05
[Update] Valid Score : (0.7554 => 0.7952) Save Parameter

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:43<00:00,  1.37s/it]
[3/6] Train & Validation
















































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81/81 [09:52<00:00,  7.06s/it]





















 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 25/26 [00:43<00:01,  1.72s/it]
[3/6] Train Loss: 0.5418000221252441
[3/6] Valid Loss: 0.5533000230789185
[3/6] Pearson Score: 0.8126
[3/6] Gradient Norm: 530.9201049804688
[3/6] lr: 2.9252577875136276e-05
[Update] Valid Score : (0.7952 => 0.8126) Save Parameter

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:43<00:00,  1.37s/it]
[4/6] Train & Validation
















































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81/81 [09:52<00:00,  7.06s/it]





















 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 25/26 [00:43<00:01,  1.72s/it]
[4/6] Train Loss: 0.5299000144004822
[4/6] Valid Loss: 0.555899977684021
[4/6] Pearson Score: 0.8139
[4/6] Gradient Norm: 581.10009765625
[4/6] lr: 1.4987976651269788e-05
[Update] Valid Score : (0.8126 => 0.8139) Save Parameter

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:43<00:00,  1.37s/it]
[5/6] Train & Validation
















































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81/81 [09:52<00:00,  7.06s/it]





















 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 25/26 [00:43<00:01,  1.72s/it]
[5/6] Train Loss: 0.5232999920845032
[5/6] Valid Loss: 0.5566999912261963
[5/6] Pearson Score: 0.818
[5/6] Gradient Norm: 621.8455200195312
[5/6] lr: 4.030786206655626e-06
[Update] Valid Score : (0.8139 => 0.8180) Save Parameter

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:43<00:00,  1.37s/it]
  0%|                                                                                                                         | 0/81 [00:00<?, ?it/s]









































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81/81 [10:01<00:00,  7.11s/it]





















100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:43<00:00,  1.38s/it]
  0%|                                                                                                                         | 0/26 [00:00<?, ?it/s]
[6/6] Train Loss: 0.5206999778747559
[6/6] Valid Loss: 0.5572999715805054
[6/6] Pearson Score: 0.8179
[6/6] Gradient Norm: 675.8956909179688






















100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:43<00:00,  1.38s/it]
Fold[1/3] SWA Loss: 0.7419999837875366
Fold[1/3] SWA Pearson Score: -0.2931