Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']
- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                           | 0/84 [00:00<?, ?it/s]
  grad_norm = torch.nn.utils.clip_grad_norm(                                                                                    | 0/84 [00:00<?, ?it/s]
/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "


















































































/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "


















 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████          | 21/23 [00:36<00:03,  1.73s/it]
[1/20] Train Loss: 0.6486999988555908
[1/20] Valid Loss: 0.6247000098228455
[1/20] Pearson Score: 0.5901
[1/20] Gradient Norm: 305967.125
[1/20] lr: 2.5e-05
[Update] Valid Score : (-inf => 0.5901) Save Parameter

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.36s/it]
  0%|                                                                                                                           | 0/84 [00:00<?, ?it/s]



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:47<00:00,  4.83s/it]



















 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 22/23 [00:38<00:01,  1.73s/it]
[2/20] Train Loss: 0.6126999855041504
[2/20] Valid Loss: 0.5956000089645386
[2/20] Pearson Score: 0.6908
[2/20] Gradient Norm: 277014.40625
[2/20] lr: 5e-05
[Update] Valid Score : (0.5901 => 0.6908) Save Parameter

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
[3/20] Train & Validation

























































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:46<00:00,  4.83s/it]















 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████          | 21/23 [00:36<00:03,  1.73s/it]
[3/20] Train Loss: 0.5846999883651733
[3/20] Valid Loss: 0.578000009059906
[3/20] Pearson Score: 0.7402
[3/20] Gradient Norm: 126404.6875
[3/20] lr: 4.849231551964771e-05
[Update] Valid Score : (0.6908 => 0.7402) Save Parameter

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
[4/20] Train & Validation



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]


















 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████          | 21/23 [00:36<00:03,  1.73s/it]
[4/20] Train Loss: 0.5706999897956848
[4/20] Valid Loss: 0.5727999806404114
[4/20] Pearson Score: 0.7587
[4/20] Gradient Norm: 553048.5
[4/20] lr: 4.415111107797445e-05
[Update] Valid Score : (0.7402 => 0.7587) Save Parameter

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
[5/20] Train & Validation



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]


















 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████          | 21/23 [00:36<00:03,  1.73s/it]
[5/20] Train Loss: 0.5656999945640564
[5/20] Valid Loss: 0.5695000290870667
[5/20] Pearson Score: 0.7781
[5/20] Gradient Norm: 170256.40625
[5/20] lr: 3.7500000000000003e-05
[Update] Valid Score : (0.7587 => 0.7781) Save Parameter

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
  0%|                                                                                                                           | 0/84 [00:00<?, ?it/s]



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]


















 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████          | 21/23 [00:36<00:03,  1.73s/it]
[6/20] Train Loss: 0.5576000213623047
[6/20] Valid Loss: 0.5623000264167786
[6/20] Pearson Score: 0.789
[6/20] Gradient Norm: 213112.921875
[6/20] lr: 2.9341204441673266e-05
[Update] Valid Score : (0.7781 => 0.7890) Save Parameter

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
[7/20] Train & Validation



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]


















 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████          | 21/23 [00:36<00:03,  1.73s/it]
[7/20] Train Loss: 0.5544000267982483
[7/20] Valid Loss: 0.5641999840736389
[7/20] Pearson Score: 0.7916
[7/20] Gradient Norm: 232814.4375
[7/20] lr: 2.0658795558326743e-05
[Update] Valid Score : (0.7890 => 0.7916) Save Parameter

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
[8/20] Train & Validation



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]


















 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████          | 21/23 [00:36<00:03,  1.73s/it]
[8/20] Train Loss: 0.552299976348877
[8/20] Valid Loss: 0.565500020980835
[8/20] Pearson Score: 0.7941
[8/20] Gradient Norm: 377634.53125
[8/20] lr: 1.2500000000000006e-05
[Update] Valid Score : (0.7916 => 0.7941) Save Parameter

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
  0%|                                                                                                                           | 0/84 [00:00<?, ?it/s]



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]



















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
[9/20] Train Loss: 0.5503000020980835
[9/20] Valid Loss: 0.5582000017166138
[9/20] Pearson Score: 0.7987
[9/20] Gradient Norm: 305468.84375
[9/20] lr: 5.848888922025553e-06
[Update] Valid Score : (0.7941 => 0.7987) Save Parameter
Best Score: 0.7986872818189451
  0%|                                                                                                                           | 0/84 [00:00<?, ?it/s]



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]


















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
  0%|                                                                                                                           | 0/84 [00:00<?, ?it/s]
[10/20] Train Loss: 0.5480999946594238
[10/20] Valid Loss: 0.5587999820709229
[10/20] Pearson Score: 0.7982
[10/20] Gradient Norm: 417691.375
[10/20] lr: 1.5076844803522922e-06



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]


















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
  0%|                                                                                                                           | 0/84 [00:00<?, ?it/s]
[11/20] Train Loss: 0.5476999878883362
[11/20] Valid Loss: 0.5594000220298767
[11/20] Pearson Score: 0.7984
[11/20] Gradient Norm: 203235.890625
[11/20] lr: 5e-05



















































































100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [06:45<00:00,  4.83s/it]



















100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:38<00:00,  1.32s/it]
[12/20] Train Loss: 0.5519000291824341
[12/20] Valid Loss: 0.5612999796867371
[12/20] Pearson Score: 0.7927
[12/20] Gradient Norm: 169419.234375
[12/20] lr: 4.849231551964771e-05
Early STOP