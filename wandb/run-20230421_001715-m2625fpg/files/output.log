Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']
- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
                                                                                                                                                      /home/qcqced/바탕화면/ML_Test/UPPPM/trainer/trainer.py:141: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  grad_norm = torch.nn.utils.clip_grad_norm(                                                                                 | 0/1311 [00:00<?, ?it/s]
[1/12] Train & Validation










































































































































































































































































































































































/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
















 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 376/388 [00:35<00:01, 10.65it/s]
[1/12] Train Loss: 0.6306999921798706
[1/12] Valid Loss: 0.5776000022888184
[1/12] Pearson Score: 0.7832
[1/12] Gradient Norm: 981.3961181640625
[1/12] lr: 1.6666666666666667e-05
[Update] Valid Score : (-inf => 0.7832) Save Parameter

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:36<00:00, 10.66it/s]
[2/12] Train & Validation










































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1311/1311 [12:06<00:00,  1.82it/s]

















 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 376/388 [00:35<00:01, 10.57it/s]
[2/12] Train Loss: 0.5871999859809875
[2/12] Valid Loss: 0.5651999711990356
[2/12] Pearson Score: 0.8063
[2/12] Gradient Norm: 927.4912719726562
[2/12] lr: 1.8936326403234125e-05
[Update] Valid Score : (0.7832 => 0.8063) Save Parameter

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:36<00:00, 10.68it/s]
[3/12] Train & Validation








































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1311/1311 [12:02<00:00,  1.82it/s]

















 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 376/388 [00:35<00:01, 10.66it/s]
[3/12] Train Loss: 0.5641999840736389
[3/12] Valid Loss: 0.5611000061035156
[3/12] Pearson Score: 0.8282
[3/12] Gradient Norm: 990.3038940429688
[3/12] lr: 1.5000000000000002e-05
[Update] Valid Score : (0.8063 => 0.8282) Save Parameter

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:36<00:00, 10.69it/s]
[4/12] Train & Validation








































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1311/1311 [12:02<00:00,  1.81it/s]

















 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 376/388 [00:35<00:01, 10.68it/s]
[4/12] Train Loss: 0.5533999800682068
[4/12] Valid Loss: 0.5573999881744385
[4/12] Pearson Score: 0.8355
[4/12] Gradient Norm: 993.163330078125
[4/12] lr: 9.418551710895241e-06
[Update] Valid Score : (0.8282 => 0.8355) Save Parameter

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:36<00:00, 10.68it/s]
[5/12] Train & Validation







































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1311/1311 [12:01<00:00,  1.81it/s]


















100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:36<00:00, 10.71it/s]
[5/12] Train Loss: 0.5422000288963318
[5/12] Valid Loss: 0.5561000108718872
[5/12] Pearson Score: 0.8445
[5/12] Gradient Norm: 955.7548828125
[5/12] lr: 4.028414082972141e-06
[Update] Valid Score : (0.8355 => 0.8445) Save Parameter
Best Score: 0.8444857685349236
  0%|                                                                                                                | 1/1311 [00:00<11:40,  1.87it/s]








































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1311/1311 [12:01<00:00,  1.82it/s]

















 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 382/388 [00:35<00:00, 10.59it/s]
[6/12] Train Loss: 0.536899983882904
[6/12] Valid Loss: 0.5594000220298767
[6/12] Pearson Score: 0.8429
[6/12] Gradient Norm: 990.9575805664062
[6/12] lr: 6.030737921409158e-07
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:36<00:00, 10.63it/s]







































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1311/1311 [12:01<00:00,  1.80it/s]
















100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:36<00:00, 10.64it/s]
  0%|                                                                                                                        | 0/1311 [00:00<?, ?it/s]
[7/12] Train Loss: 0.5396999716758728
[7/12] Valid Loss: 0.5755000114440918
[7/12] Pearson Score: 0.8269
[7/12] Gradient Norm: 1008.5045166015625
[7/12] lr: 1.973044870579824e-05








































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1311/1311 [12:02<00:00,  1.82it/s]


















 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 386/388 [00:36<00:00, 10.64it/s]
[8/12] Train Loss: 0.5450000166893005
[8/12] Valid Loss: 0.5619000196456909
[8/12] Pearson Score: 0.8409
[8/12] Gradient Norm: 1000.8270263671875
[8/12] lr: 1.6862416378687336e-05

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 388/388 [00:36<00:00, 10.64it/s]