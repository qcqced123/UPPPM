Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight']
- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/qcqced/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                          | 0/41 [00:00<?, ?it/s]
  grad_norm = torch.nn.utils.clip_grad_norm(                                                                                   | 0/41 [00:00<?, ?it/s]







































/home/qcqced/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "










100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.27s/it]
[1/24] Train Loss: 0.6474999785423279
[1/24] Valid Loss: 0.6087999939918518
[1/24] Pearson Score: 0.64
[1/24] Gradient Norm: 35.26729965209961
[1/24] lr: 8.341810783316379e-06
[Update] Valid Score : (-inf => 0.6400) Save Parameter
Best Score: 0.6399872790896171
  0%|                                                                                                                          | 0/41 [00:00<?, ?it/s]








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:52<00:00,  7.09s/it]











100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.28s/it]
[2/24] Train Loss: 0.595300018787384
[2/24] Valid Loss: 0.5656999945640564
[2/24] Pearson Score: 0.7676
[2/24] Gradient Norm: 78.168701171875
[2/24] lr: 1.6683621566632758e-05
[Update] Valid Score : (0.6400 => 0.7676) Save Parameter
Best Score: 0.7676109821885799
  0%|                                                                                                                          | 0/41 [00:00<?, ?it/s]








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:51<00:00,  7.02s/it]










100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]
[3/24] Train Loss: 0.5717999935150146
[3/24] Valid Loss: 0.5579000115394592
[3/24] Pearson Score: 0.7992
[3/24] Gradient Norm: 112.98770141601562
[3/24] lr: 1.9846532076672343e-05
[Update] Valid Score : (0.7676 => 0.7992) Save Parameter
Best Score: 0.7992220392702725
  0%|                                                                                                                          | 0/41 [00:00<?, ?it/s]








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:50<00:00,  7.03s/it]









 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.71s/it]
[4/24] Train Loss: 0.5559999942779541
[4/24] Valid Loss: 0.5475999712944031
[4/24] Pearson Score: 0.8123
[4/24] Gradient Norm: 132.4709014892578
[4/24] lr: 1.8931007819078825e-05
[Update] Valid Score : (0.7992 => 0.8123) Save Parameter

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]
[5/24] Train & Validation








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:50<00:00,  7.03s/it]









 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.73s/it]
[5/24] Train Loss: 0.54830002784729
[5/24] Valid Loss: 0.5449000000953674
[5/24] Pearson Score: 0.8227
[5/24] Gradient Norm: 148.7779998779297
[5/24] lr: 1.7263574866522983e-05
[Update] Valid Score : (0.8123 => 0.8227) Save Parameter

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.28s/it]
[6/24] Train & Validation








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:54<00:00,  7.02s/it]










 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.71s/it]
[6/24] Train Loss: 0.5428000092506409
[6/24] Valid Loss: 0.5428000092506409
[6/24] Pearson Score: 0.8282
[6/24] Gradient Norm: 170.58349609375
[6/24] lr: 1.4984615733575584e-05
[Update] Valid Score : (0.8227 => 0.8282) Save Parameter

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]
[7/24] Train & Validation








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:50<00:00,  7.13s/it]









 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.70s/it]
[7/24] Train Loss: 0.5365999937057495
[7/24] Valid Loss: 0.5425000190734863
[7/24] Pearson Score: 0.8316
[7/24] Gradient Norm: 186.97129821777344
[7/24] lr: 1.2285997813283395e-05
[Update] Valid Score : (0.8282 => 0.8316) Save Parameter

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]
[8/24] Train & Validation








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:49<00:00,  7.01s/it]









 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.70s/it]
[8/24] Train Loss: 0.5335000157356262
[8/24] Valid Loss: 0.5453000068664551
[8/24] Pearson Score: 0.8347
[8/24] Gradient Norm: 198.88580322265625
[8/24] lr: 9.39491990781453e-06
[Update] Valid Score : (0.8316 => 0.8347) Save Parameter

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]
[9/24] Train & Validation








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:49<00:00,  7.02s/it]









 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.71s/it]
[9/24] Train Loss: 0.5306000113487244
[9/24] Valid Loss: 0.5425000190734863
[9/24] Pearson Score: 0.8351
[9/24] Gradient Norm: 214.17010498046875
[9/24] lr: 6.554784179497382e-06
[Update] Valid Score : (0.8347 => 0.8351) Save Parameter

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]
[10/24] Train & Validation








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:49<00:00,  7.01s/it]










 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.70s/it]
[10/24] Train Loss: 0.5285999774932861
[10/24] Valid Loss: 0.5430999994277954
[10/24] Pearson Score: 0.8381
[10/24] Gradient Norm: 219.9394989013672
[10/24] lr: 4.0047039280015355e-06
[Update] Valid Score : (0.8351 => 0.8381) Save Parameter

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]
[11/24] Train & Validation








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:49<00:00,  7.02s/it]









 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.71s/it]
[11/24] Train Loss: 0.5273000001907349
[11/24] Valid Loss: 0.54339998960495
[11/24] Pearson Score: 0.8382
[11/24] Gradient Norm: 229.8883056640625
[11/24] lr: 1.959372450297945e-06
[Update] Valid Score : (0.8381 => 0.8382) Save Parameter

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]
[12/24] Train & Validation








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:51<00:00,  7.06s/it]










 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.72s/it]
[12/24] Train Loss: 0.5266000032424927
[12/24] Valid Loss: 0.5436999797821045
[12/24] Pearson Score: 0.8374
[12/24] Gradient Norm: 240.20849609375
[12/24] lr: 5.909878401874181e-07
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.27s/it]








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:50<00:00,  7.01s/it]










 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 12/13 [00:20<00:01,  1.70s/it]
[13/24] Train Loss: 0.525600016117096
[13/24] Valid Loss: 0.5436999797821045
[13/24] Pearson Score: 0.8373
[13/24] Gradient Norm: 251.98350524902344
[13/24] lr: 1.475549298903145e-08
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.26s/it]








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [04:49<00:00,  6.99s/it]









 85%|███████████████████████████████████████████████████████████████████████████████████████████████▌                 | 11/13 [00:18<00:03,  1.70s/it]
[14/24] Train Loss: 0.5270000100135803
[14/24] Valid Loss: 0.5436999797821045
[14/24] Pearson Score: 0.8344
[14/24] Gradient Norm: 261.6969909667969
[14/24] lr: 1.9720811128880196e-05

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.25s/it]